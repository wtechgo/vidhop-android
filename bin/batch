#!/bin/bash

function batch_help() {
  echo " Title: batch"
  echo " Description: Do work in bulk aka batch processing."
  echo " Commands:"
  echo "    dlalist [<LIST_FILE_PATH>]     => download all URLs in list file at /VidHop/import/list/dla.list"
  echo "    dlaclist [<LIST_FILE_PATH>] => download all URLs in list file at /VidHop/import/list/dlac.list"
  echo "    dlacilist [<LIST_FILE_PATH>]   => download all URLs in list file at /VidHop/import/list/dlaci.list"
  echo "    dlalbumlist [<LIST_FILE_PATH>] => download all URLs in list file at /VidHop/import/list/dlalbum.list"
  echo "    dlapllist [<LIST_FILE_PATH>]   => download all URLs in list file at /VidHop/import/list/dlapl.list"
  echo "    dlaplilist [<LIST_FILE_PATH>]  => download all URLs in list file at /VidHop/import/list/dlapli.list"
  echo "    dlclist [<LIST_FILE_PATH>]     => download all URLs in list file at /VidHop/import/list/dlc.list"
  echo "    dlcilist [<LIST_FILE_PATH>]    => download all URLs in list file at /VidHop/import/list/dlci.list"
  echo "    dlpodlist [<LIST_FILE_PATH>]   => download all URLs in list file at /VidHop/import/list/dlpod.list"
  echo "    dltlist [<LIST_FILE_PATH>]     => download all URLs in list file at /VidHop/import/list/dlt.list"
  echo "    dlvlist [<LIST_FILE_PATH>]     => download all URLs in list file at /VidHop/import/list/dlv.list"
  echo "    dlvilist [<LIST_FILE_PATH>]    => download all URLs in list file at /VidHop/import/list/dlvi.list"
  echo "    dlvpllist [<LIST_FILE_PATH>]   => download all URLs in list file at /VidHop/import/list/dlvpl.list"
}

function dlalist () {
  list="$import_list_dir/dla.list"
  [ -n "$1" ] && list="$import_list_dir/$1"
  [ ! -f "$list" ] && echo "no file found at path '$list' which should point to a file containing only URLs, abort" && return

  while read -r url; do
    dla "$url"
  done <"$list"
}

function dlaclist () {
  list="$import_list_dir/dlac.list"
  [ -n "$1" ] && list="$import_list_dir/$1"
  [ ! -f "$list" ] && echo "no file found at path '$list' which should point to a file containing only URLs, abort" && return

  while read -r url; do
    dlac "$url"
  done <"$list"
}

function dlacilist () {
  list="$import_list_dir/dlaci.list"
  [ -n "$1" ] && list="$import_list_dir/$1"
  [ ! -f "$list" ] && echo "no file found at path '$list' which should point to a file containing only URLs, abort" && return

  while read -r url; do
    dlaci "$url"
  done <"$list"
}

function dlalbumlist () {
  list="$import_list_dir/dlalbum.list"
  [ -n "$1" ] && list="$import_list_dir/$1"
  [ ! -f "$list" ] && echo "no file found at path '$list' which should point to a file containing only URLs, abort" && return

  while read -r url; do
    dlalbum "$url"
  done <"$list"
}

function dlapllist () {
  list="$import_list_dir/dlapl.list"
  [ -n "$1" ] && list="$import_list_dir/$1"
  [ ! -f "$list" ] && echo "no file found at path '$list' which should point to a file containing only URLs, abort" && return

  while read -r url; do
    dlapl "$url"
  done <"$list"
}

function dlaplilist () {
  list="$import_list_dir/dlapli.list"
  [ -n "$1" ] && list="$import_list_dir/$1"
  [ ! -f "$list" ] && echo "no file found at path '$list' which should point to a file containing only URLs, abort" && return

  while read -r url; do
    dlapli "$url"
  done <"$list"
}

function dlclist () {
  list="$import_list_dir/dlc.list"
  [ -n "$1" ] && list="$import_list_dir/$1"
  [ ! -f "$list" ] && echo "no file found at path '$list' which should point to a file containing only URLs, abort" && return

  while read -r url; do
    dlc "$url"
  done <"$list"
}

function dlcilist () {
  list="$import_list_dir/dlci.list"
  [ -n "$1" ] && list="$import_list_dir/$1"
  [ ! -f "$list" ] && echo "no file found at path '$list' which should point to a file containing only URLs, abort" && return

  while read -r url; do
    dlci "$url"
  done <"$list"
}

function dlpodlist () {
  list="$import_list_dir/dlpod.list"
  [ -n "$1" ] && list="$import_list_dir/$1"
  [ ! -f "$list" ] && echo "no file found at path '$list' which should point to a file containing only URLs, abort" && return

  while read -r url; do
    dlpod "$url"
  done <"$list"
}

function dltlist () {
  list="$import_list_dir/dlt.list"
  [ -n "$1" ] && list="$import_list_dir/$1"
  [ ! -f "$list" ] && echo "no file found at path '$list' which should point to a file containing only URLs, abort" && return

  while read -r url; do
    dlt "$url"
  done <"$list"
}

function dlvlist () {
  list="$import_list_dir/dlv.list"
  [ -n "$1" ] && list="$import_list_dir/$1"
  [ ! -f "$list" ] && echo "no file found at path '$list' which should point to a file containing only URLs, abort" && return

  while read -r url; do
    dlv "$url"
  done <"$list"
}

function dlvilist () {
  list="$import_list_dir/dlvi.list"
  [ -n "$1" ] && list="$import_list_dir/$1"
  [ ! -f "$list" ] && echo "no file found at path '$list' which should point to a file containing only URLs, abort" && return

  while read -r url; do
    dlvi "$url"
  done <"$list"
}

function dlvpllist () {
  list="$import_list_dir/dlvpl.list"
  [ -n "$1" ] && list="$import_list_dir/$1"
  [ ! -f "$list" ] && echo "no file found at path '$list' which should point to a file containing only URLs, abort" && return

  while read -r url; do
    dlvpl "$url"
  done <"$list"
}

function dlvplilist () {
  list="$import_list_dir/dlvpli.list"
  [ -n "$1" ] && list="$import_list_dir/$1"
  [ ! -f "$list" ] && echo "no file found at path '$list' which should point to a file containing only URLs, abort" && return

  while read -r url; do
    dlvpli "$url"
  done <"$list"
}

# Write urls from channels to file.
function export_channel_urls() {
  youtube_channels_1="$import_dir/urls_export.txt"
  url_stream_txt="$import_dir/url_stream.txt"
  channel_stream_json="$import_dir/channel_stream.json"
  all_channels_json="$import_dir/all_channels.json"
  error_log="$import_dir/error.log"

  rm "$youtube_channels_1" "$url_stream_txt" "$channel_stream_json" "$all_channels_json" "$error_log"

  while read -r json_file; do
    channel_name=$(channel_name_from_json_file "$json_file")
    channel_url=$(channel_url_from_json_file "$json_file")

    [ -z "$channel_url" ] && echo "skipped processing $json_file \n> url of the channel_name was missing" &&
      echo "[$(date)] channel_name url missing in $json_file" >>"$error_log" && continue

    echo processing "$channel_name"...
    echo "$channel_url" >>"$url_stream_txt"
    printf "{\"channel_name\": \"%s\", \"channel_url\": \"%s\"}\n" "$channel_name" "$channel_url" >>"$channel_stream_json"
  done < <(find "$channels_meta_dir" ! -name "all_channels*.json" ! -name "avatar_data*.json" -type f -iname "*.json")

  allchans=$(jq -s '.' "$channel_stream_json" | jq 'sort_by(.channel_name) | unique_by(.channel_url)')

  jq '.[].channel_url' <<<"$allchans" | tr -d '"' >"$youtube_channels_1"
  jq <<<"$allchans" >"$all_channels_json"
}

function can_add_jobs() {
  [ "$(pgrep yt-dlp | wc -l)" -gt 6 ] && echo false || echo true
}

function jobs_done() {
  [ "$(pgrep yt-dlp)" ] && echo false || echo true
}

# Download metadata for all channels that have a json file.
function syncchannels_json_based() {
  while read -r json_file; do
    channel_url=$(channel_url_from_json_file "$json_file")
    dlci "$channel_url" &# ! spawns multiple processes in the background
  done < <(find "$channels_meta_dir" ! -name "avatar_*json" -type f -iname "*.json")
}

# Import URLs line per line from $meta_dir/import.txt.
# Choose dlv or dlvi mode by passing it as and argument.
# Example 1: import dlv  |  exemple 2: import dlvi
# Note: -a import_file.txt is another possibility
function import() {
  mode=$([ -z "$1" ] && echo dlv || echo "$1")
  urls="$import_dir/urls.txt"

  if [[ $mode == "dlv" ]]; then
    while read -r url; do
      dlv "$url" &
    done <"$urls"

  elif [[ $mode == "dlvi" ]]; then
    while read -r url; do
      dlvi "$url" &
    done <"$urls"

  elif [[ $mode == "dlc" ]]; then
    while read -r url; do
      dlc "$url" &
    done <"$urls"

  elif [[ $mode == "dlci" ]]; then
    while read -r url; do
      dlci "$url" &
    done <"$urls"
  fi
}

# Merge subset metadata json of all channels and write one big file to channels metadata root directory.
function squashjson() {
  unset json

  while read -r chanjson; do
    echo "processing $chanjson..."
    channel_name=$(channel_name_from_json_file "$chanjson")
    channel_url=$(channel_url_from_json_file "$chanjson")

    channel_thumbnail_path=$(jq '.channel_thumbnail_path' "$chanjson" | tr -d '"')
    channel_thumbnail_url=$(jq '.channel_thumbnail_url' "$chanjson" | tr -d '"')
    platform=$(jq '.platform' "$chanjson")

    json+=$(
      jq --arg channel_name "$channel_name" \
        --arg channel_url "$channel_url" \
        --arg channel_thumbnail_path "$channel_thumbnail_path" \
        --arg channel_thumbnail_url "$channel_thumbnail_url" \
        --arg platform "$platform" \
        '.entries[] |
            {
              title: .title,
              description: .description,
              url: .webpage_url,
              thumbnail: .thumbnail,
              channel_name: $channel_name,
              channel_url: $channel_url,
              channel_thumbnail_path: $channel_thumbnail_path,
              channel_thumbnail_url: $channel_thumbnail_url,
              platform: $platform
            }
          ' "$chanjson"
    )
    unset channel_thumbnail_path channel_thumbnail_url platform
  done < <(find "$channels_meta_dir" ! -name "all_channels*.json" ! -name "avatar_data*.json" -type f -iname "*.json")

  jq -s 'map(select(.title != null))' <<<"$json" >"$channels_meta_dir/all_channels".json # remove { null: null} objects
  jq -s <<<"$json" >"$import_dir/squashed.json"
  unset json
}

# Functions for manual data repair and troubleshoot.
# --------------------------------------------------

function update_archives_from_json_metadata() {
  while read -r json_file; do
    echo processing "$json_file"
    json=$(jq . "$json_file")
    save_channel_entries_to_archive
  done < <(find "$channels_meta_dir" ! -name "all_channels*.json" -type f -iname "*.json")
}
function inspect_field_all_channels() {
  while read -r json_file; do
    jq '.categories' "$json_file"
  done < <(find "$channels_meta_dir" ! -name "avatar_*json" -type f -iname "*.json")
}

# does not work
function sort_channel_entries_desc() {
  echo starting sort all channel entries descending by upload date
  while read -r json_file; do
    unset json && echo processing "$json_file"...

    json=$(jq . "$json_file")
    entries=$(jq ".entries | sort_by(.upload_date) | reverse" <<<"$json")
    json=$(jq -s '.[0].entries = .[1] | .[0]' <<<"$json" <<<"$entries") # workaround for --argjson value too large

    jq <<<"$json" >"$json_file"
  done < <(find "$channels_meta_dir" ! -name "all_channels*.json" ! -name "avatar_data*json" -type f -iname "*.json")
}

function list_channel_avatars() {
  while read -r channelDir; do
    echo "channel: $channelDir"
    # doesn't work because platform name is missing
    ll "$channelDir/$channelDir.jpg" 2>/dev/null
    ll "$channelDir/$channelDir.webp" 2>/dev/null
    ll "$channelDir/$channelDir.png" 2>/dev/null
  done < <(find "$channels_meta_dir" ! -name "all_channels*.json" -type f -iname "*.json")
}

function fetch_avatars_by_json() {
  while read -r json_file; do
    echo processing "$json_file"...
    channel_name=$(channel_name_from_json_file "$json_file")
    channel_url=$(channel_url_from_json_file "$json_file")
    python "$scrape_channel_avatar_img_py" --channel-url "$channel_url" --channel-name "$channel_name"
  done < <(find "$channels_meta_dir" ! -name "all_channels*.json" ! -name "avatar_data*json" -type f -iname "*.json")
}

function merge_avatar_json() { # jq merge overwrites previous fields.
  while read -r json_file; do
    echo processing "$json_file"...
    channel_name=$(channel_name_from_json_file "$json_file")
    avatar_json_file=$(find "$channels_meta_dir/$channel_name" -iname "avatar*json")
    avatar_json=$(jq . "$avatar_json_file")
    [ -z "$avatar_json" ] && continue

    json=$(jq '.' "$json_file")
    jq -s '.[0] += .[1] | .[0]' <<<"$json" <<<"$avatar_json" >"$json_file"
  done < <(find "$channels_meta_dir" ! -name "all_channels*.json" ! -name "avatar*json" -type f -iname "*.json")
}
